我们已经讨论过向量化是如何显著地加速代码运行速度，本节中我们将会谈及向量化如何实现在logistic回归上的。这样就能同时处理整个训练集来实现梯度下降法的一步迭代。针对整个训练集的一步迭代不需要使用任何显示for循环。

先回顾瞎logistic回归的正向传播步骤,若有m个样本，那么对第一个样本进行预测：

[公式]

然后继续对第二个训练样本做一个预测：

[公式]

依次进行计算直至所有样本。

我们曾经定义过一个大写矩阵X，作为训练输入，不同的列堆叠到一起：


现在我们来看一下如何计算 [公式] 。构建一个1*m的矩阵，实际上就是一个行向量,然后我们计算 [公式] ,由矩阵乘法： [公式] 可以改写为 [公式]


对比以上公式定义可有： [公式]

所以我们仅需一行代码就行完成预测值Z的计算。Z是一个1*m的矩阵由全部z堆叠而成。计算 [公式] 使用numpy进行处理即可。以上将数据集的遍历转换为矩阵乘法，且仅需一行代码就可实现。

因公式格式问题,完整博文详见知乎：https://zhuanlan.zhihu.com/p/407568949
